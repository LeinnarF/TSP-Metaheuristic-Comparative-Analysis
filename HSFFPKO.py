# -*- coding: utf-8 -*-
"""HSFFPKO.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1A0litfPhAVDvYZ8X0-7VMzgmT23pwQa3
"""

import time
from typing import Callable, Tuple, Union, Sequence
import numpy as np
import random
import string
import time

ArrayLike = Union[float, int, Sequence[float], np.ndarray]

import numpy as np
from typing import Tuple, Union, Sequence

ArrayLike = Union[float, int, Sequence[float], np.ndarray]

def initialization(
    N: int,
    dim: int,
    ub: ArrayLike,
    lb: ArrayLike,
    rng: np.random.Generator = None
) -> Tuple[np.ndarray, np.ndarray, np.ndarray]:
    """
    Initialize the first population of search agents.

    Parameters
    ----------
    N : int
        Number of agents (population size).
    dim : int
        Problem dimensionality.
    ub : float | sequence | np.ndarray
        Upper bound(s). If scalar/length-1, applied to all dimensions.
        If array-like with length == dim, applied per-dimension.
    lb : float | sequence | np.ndarray
        Lower bound(s). Same broadcasting rules as `ub`.
    rng : np.random.Generator, optional
        Random generator for reproducibility. If None, uses default_rng().

    Returns
    -------
    x : (N, dim) np.ndarray
        Initialized population.
    new_lb : (dim,) np.ndarray
        Lower bounds expanded per dimension.
    new_ub : (dim,) np.ndarray
        Upper bounds expanded per dimension.
    """
    if rng is None:
        rng = np.random.default_rng()

    ub_arr = np.asarray(ub, dtype=float).ravel()
    lb_arr = np.asarray(lb, dtype=float).ravel()

    boundary = ub_arr.size

    if boundary == 1:
        # Single scalar bound for all dimensions
        ub_val = float(ub_arr[0])
        lb_val = float(lb_arr[0])
        if ub_val < lb_val:
            raise ValueError(f"Upper bound {ub_val} < lower bound {lb_val}.")
        new_lb = np.full(dim, lb_val, dtype=float)
        new_ub = np.full(dim, ub_val, dtype=float)
        x = rng.random((N, dim)) * (ub_val - lb_val) + lb_val
    else:
        # Per-dimension bounds; require length == dim
        if lb_arr.size != dim or ub_arr.size != dim:
            raise ValueError(
                f"When providing vector bounds, lengths must equal dim={dim} "
                f"(got len(lb)={lb_arr.size}, len(ub)={ub_arr.size})."
            )
        if np.any(ub_arr < lb_arr):
            idx = np.where(ub_arr < lb_arr)[0]
            raise ValueError(f"Upper bound < lower bound at dimensions: {idx.tolist()}")
        new_lb = lb_arr.astype(float, copy=False)
        new_ub = ub_arr.astype(float, copy=False)
        # Vectorized sampling per dimension
        x = rng.random((N, dim)) * (new_ub - new_lb) + new_lb

    return x, new_lb, new_ub


def HSFFPKO(
    Popsize: int,
    Maxiteration: int,
    LB: ArrayLike,
    UB: ArrayLike,
    Dim: int,
    Fobj: Callable[[np.ndarray], float],
    rng: np.random.Generator = None,
    *,
    # Hovering Scouts (HS)
    scouts_rate: float = 0.10,     # fraction of population acting as scouts
    scouts_every: int = 1,         # HS frequency (iterations)
    scout_bias: float = 0.05,      # tiny bias toward global best (0 disables)
    # Foraging Flocks (FF)
    num_flocks: int = 5,           # number of temporary flocks (≥2)
    flock_every: int = 5,          # FF frequency (iterations)
    ff_exploit: float = 0.6,       # 0..1: weight toward local leader vs centroid
    radius_frac: float = 0.10,     # initial foraging radius as frac of (UB-LB)
    radius_decay: float = 0.95,    # multiplicative decay per FF invocation
) -> Tuple[float, np.ndarray, np.ndarray]:
    """
    Pied Kingfisher Optimizer (PKO) with Hovering Scouts and Foraging Flocks.

    - HS: a subset of agents performs short, self-scaled Gaussian probes (hovering)
          with optional tiny bias toward the global best; accept-if-better.
    - FF: periodically partition population into K flocks; each flock forages
          around its centroid and leader with a shrinking radius.

    Returns
    -------
    Best_fitness : float
    Best_position : (Dim,) array
    Convergence_curve : (Maxiteration,) array
    """
    if rng is None:
        rng = np.random.default_rng()

    start = time.time()
    BF = 8  # beating Factor
    Crest_angles = 2 * np.pi * rng.random()

    # Initialization
    X, LBv, UBv = initialization(Popsize, Dim, UB, LB, rng)
    Fitness = np.zeros(Popsize, dtype=float)
    Convergence_curve = np.zeros(Maxiteration, dtype=float)

    # Evaluate initial population
    for i in range(Popsize):
        Fitness[i] = float(Fobj(X[i, :]))

    # Sort & pick best
    sorted_idx = np.argsort(Fitness)
    Best_position = X[sorted_idx[0], :].copy()
    Best_fitness = float(Fitness[sorted_idx[0]])
    Convergence_curve[0] = Best_fitness

    # Predatory Efficiency schedule
    PEmax, PEmin = 0.5, 0.0

    # Helpers
    def clamp(arr: np.ndarray) -> np.ndarray:
        return np.minimum(np.maximum(arr, LBv), UBv)

    # Foraging radius (shrinks at each FF step)
    domain_span = np.maximum(UBv - LBv, 1e-12)
    forage_radius = radius_frac * domain_span

    # Main loop
    for t in range(1, Maxiteration + 1):
        o = np.exp(-t / Maxiteration) ** 2

        # Phase 1: Exploration / Exploitation
        X_1 = np.empty_like(X)
        for i in range(Popsize):
            if rng.random() < 0.8:  # exploration
                j = i
                while j == i:
                    j = int(rng.integers(0, Popsize))

                denom = Fitness[i] if Fitness[i] != 0 else 1e-12
                beatingRate = rng.random() * (Fitness[j] / denom)
                alpha = rng.normal(0.0, 1.0, size=Dim) * 2.0 - 1.0

                if rng.random() < 0.5:
                    T = beatingRate - (t ** (1 / BF)) / (Maxiteration ** (1 / BF))
                    X_1[i, :] = X[i, :] + alpha * T * (X[j, :] - X[i, :])
                else:
                    T = (np.e - np.exp(((t - 1) / Maxiteration) ** (1 / BF))) * (np.cos(Crest_angles))
                    X_1[i, :] = X[i, :] + alpha * T * (X[j, :] - X[i, :])
            else:  # exploitation
                alpha = rng.normal(0.0, 1.0, size=Dim) * 2.0 - 1.0
                b = X[i, :] + (o ** 2) * rng.standard_normal() * Best_position
                denom = Best_fitness if Best_fitness != 0 else 1e-12
                HuntingAbility = rng.random() * (Fitness[i] / denom)
                X_1[i, :] = X[i, :] + HuntingAbility * o * alpha * (b - Best_position)

        X_1 = clamp(X_1)
        fitnessn = np.array([Fobj(X_1[i, :]) for i in range(Popsize)], dtype=float)
        improved = fitnessn < Fitness
        Fitness[improved] = fitnessn[improved]
        X[improved, :] = X_1[improved, :]

        # Global best
        idx_best = int(np.argmin(Fitness))
        if Fitness[idx_best] < Best_fitness:
            Best_fitness = float(Fitness[idx_best])
            Best_position = X[idx_best, :].copy()

        # Phase 2: Commensal association
        PE = PEmax - (PEmax - PEmin) * (t / Maxiteration)
        X_1 = np.empty_like(X)
        for i in range(Popsize):
            alpha = rng.normal(0.0, 1.0, size=Dim) * 2.0 - 1.0
            if rng.random() > (1 - PE):
                r1 = int(rng.integers(0, Popsize))
                r2 = int(rng.integers(0, Popsize))
                X_1[i, :] = X[r1, :] + o * alpha * np.abs(X[i, :] - X[r2, :])
            else:
                X_1[i, :] = X[i, :]

        X_1 = clamp(X_1)
        fitnessn = np.array([Fobj(X_1[i, :]) for i in range(Popsize)], dtype=float)
        improved = fitnessn < Fitness
        Fitness[improved] = fitnessn[improved]
        X[improved, :] = X_1[improved, :]

        # Global best
        idx_best = int(np.argmin(Fitness))
        if Fitness[idx_best] < Best_fitness:
            Best_fitness = float(Fitness[idx_best])
            Best_position = X[idx_best, :].copy()

        #  Hovering Scouts (HS)
        if scouts_rate > 0 and (t % max(1, scouts_every) == 0):
            n_scouts = max(1, int(round(scouts_rate * Popsize)))
            scout_idx = rng.choice(Popsize, size=n_scouts, replace=False)

            for ii in scout_idx:
                xi = X[ii].copy()

                # Self-scaled Gaussian probe (hovering)
                cand = xi + xi * rng.normal(size=Dim)

                if scout_bias > 0.0:
                    # tiny, signed bias toward current best (directional hovering)
                    sign_vec = np.where(rng.random(Dim) < 0.5, -1.0, 1.0)
                    cand = cand + scout_bias * sign_vec * (Best_position - cand)

                cand = clamp(cand)
                f_cand = float(Fobj(cand))
                if f_cand <= Fitness[ii]:
                    X[ii], Fitness[ii] = cand, f_cand

            # refresh best after scouts
            ii_best = int(np.argmin(Fitness))
            if Fitness[ii_best] < Best_fitness:
                Best_fitness = float(Fitness[ii_best])
                Best_position = X[ii_best, :].copy()

        # Foraging Flocks (FF)
        if num_flocks >= 2 and (t % max(1, flock_every) == 0):
            # Random partition into K flocks (balanced as possible)
            K = min(num_flocks, Popsize)
            perm = rng.permutation(Popsize)
            splits = np.array_split(perm, K)

            # For each flock: compute centroid & local leader; forage around both
            newX = X.copy()
            for flock in splits:
                if flock.size == 0:
                    continue
                F_sub = Fitness[flock]
                X_sub = X[flock]

                # centroid & leader
                centroid = X_sub.mean(axis=0)
                leader_idx = flock[int(np.argmin(F_sub))]
                leader = X[leader_idx]

                # move each member toward a convex combo of leader & centroid
                # plus isotropic noise scaled by current forage_radius
                # step balance: ff_exploit toward leader, (1-ff_exploit) toward centroid
                target = ff_exploit * leader + (1.0 - ff_exploit) * centroid

                # stochastic step within shrinking radius
                noise = rng.normal(size=(flock.size, Dim)) * forage_radius
                step = (target - X_sub) * rng.random((flock.size, 1)) + noise

                newX[flock] = X_sub + step

            # bounds + greedy
            newX = clamp(newX)
            fnew = np.array([Fobj(newX[i, :]) for i in range(Popsize)], dtype=float)
            better = fnew < Fitness
            X[better], Fitness[better] = newX[better], fnew[better]

            # shrink radius after each FF call
            forage_radius = np.maximum(forage_radius * radius_decay, 1e-12)

            # refresh best after FF
            jj_best = int(np.argmin(Fitness))
            if Fitness[jj_best] < Best_fitness:
                Best_fitness = float(Fitness[jj_best])
                Best_position = X[jj_best, :].copy()

        # Store convergence
        Convergence_curve[t - 1] = Best_fitness

    _elapsed = time.time() - start  # available if you want to log runtime
    return Best_fitness, Best_position, Convergence_curve, _elapsed


#TSP
leader_distance_matrix = np.array([
    [ 0., 20., 13., 21., 16.,  9., 17.,  5., 16., 20.],
    [13.,  0., 19., 24., 12., 22.,  5., 24.,  9., 19.],
    [16., 10.,  0., 15., 11.,  6., 23., 11.,  7., 21.],
    [15., 17.,  7.,  0.,  5.,  6., 21., 12.,  7., 18.],
    [19.,  8., 18.,  9.,  0., 22., 15., 24., 22., 10.],
    [ 6., 22., 10., 21.,  7.,  0., 17., 24., 18., 24.],
    [20., 20., 24., 17., 22.,  5.,  0.,  7., 11., 13.],
    [16., 16., 17., 14.,  8., 13., 12.,  0., 15., 16.],
    [16., 21., 23., 21., 10.,  5., 17., 18.,  0.,  6.],
    [21.,  5., 12., 18.,  6., 17., 11., 24.,  8.,  0.]
])

print(f"Shape: {leader_distance_matrix.shape}")
print(f"Sample: {leader_distance_matrix[0][:5]}...")


def tsp_totaldistance(route, dist_matrix):
    """Matrix version."""
    total = 0
    n = len(route)
    for i in range(n - 1):
        u, v = route[i], route[i + 1]
        total += dist_matrix[u, v]
    total += dist_matrix[route[-1], route[0]]  # Close tour
    return total

def universal_tsp_wrapper(dist_matrix):
    """Matrix → Fitness wrapper."""
    def fitness(position):
        route = np.argsort(position).tolist()
        return tsp_totaldistance(route, dist_matrix)
    return fitness


def run_hsffpko_Cmatrix():
    num_nodes = 10

    fobj_leader = universal_tsp_wrapper(leader_distance_matrix)

    # HSFFPKO
    Best_fitness, Best_position, Convergence_curve, runtime = HSFFPKO(
        Popsize=50,
        Maxiteration=500,
        LB=np.zeros(num_nodes),
        UB=np.ones(num_nodes) * 20,
        Dim=num_nodes,
        Fobj=fobj_leader,  # MATRIX
        scouts_rate=0.15,
        num_flocks=8
    )

    best_route = np.argsort(Best_position).tolist()
    hsff_dist = Best_fitness

    print(f"   Best Route: {best_route}")
    print(f"   Distance: {hsff_dist:.2f}")
    print(f"Runtime: {runtime:.6f}s")

    return best_route, hsff_dist, Convergence_curve, runtime

